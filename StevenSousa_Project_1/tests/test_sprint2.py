"""
Author: Steven Sousa
Prof. John Santore
Institution: Bridgewater State University - COMP490 - Senior Design & Development
Version: 12Feb2025

Description: This file contains unit tests for Project 1 - Sprint 2.
Disclaimer: These tests were primarily generated by a LLM."""

import pytest
import json
import dotenv
import os
from psycopg import sql
import psycopg
import src.Data_Processing as Data_Processing
import src.DBUtils as DBUtils

# Load environment variables
dotenv.load_dotenv()

# Assign environment variables
DB_NAME_TEST = os.getenv('DB_NAME_TEST')
DB_NAME_DEFAULT = os.getenv('DB_NAME_DEFAULT')
DB_USER_DEFAULT = os.getenv('DB_USER_DEFAULT')
DB_PASSWORD_DEFAULT = os.getenv('DB_PASSWORD_DEFAULT')
DB_HOST = os.getenv('DB_HOST')
DB_PORT = os.getenv('DB_PORT')


@pytest.fixture(scope="function")
def db_conn():
    # Admin connection for database management
    admin_conn = psycopg.connect(
        f"dbname={DB_NAME_DEFAULT} user={DB_USER_DEFAULT} password={DB_PASSWORD_DEFAULT} host={DB_HOST} port={DB_PORT}"
    )
    admin_conn.autocommit = True  # Enable autocommit to allow CREATE/DROP DATABASE
    try:
        # Drop existing test database if it exists
        with admin_conn.cursor() as cursor:
            cursor.execute(sql.SQL("DROP DATABASE IF EXISTS {}").format(sql.Identifier(DB_NAME_TEST)))

        # Create a fresh test database
        with admin_conn.cursor() as cursor:
            cursor.execute(sql.SQL("CREATE DATABASE {}").format(sql.Identifier(DB_NAME_TEST)))
            print(f"Database {DB_NAME_TEST} created.")

        # Assert that the database was created
        with admin_conn.cursor() as cursor:
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (DB_NAME_TEST,))
            assert cursor.fetchone() is not None, f"Database {DB_NAME_TEST} was not created"

        # Connect to the newly created test database for the test
        conn = psycopg.connect(
            f"dbname={DB_NAME_TEST} user={DB_USER_DEFAULT} password={DB_PASSWORD_DEFAULT} host={DB_HOST} port={DB_PORT}"
        )
        yield conn
    finally:
        # Ensure the test database connection is closed
        if 'conn' in locals() and not conn.closed:
            conn.close()

        # Give a small delay for connection to fully close
        import time
        time.sleep(0.5)  # This might not be necessary but can help in some environments

        # Cleanup - Drop the test database
        with admin_conn.cursor() as cursor:
            cursor.execute(sql.SQL("DROP DATABASE IF EXISTS {}").format(sql.Identifier(DB_NAME_TEST)))
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (DB_NAME_TEST,))
            assert cursor.fetchone() is None, f"Database {DB_NAME_TEST} was not dropped"
            print(f"Database {DB_NAME_TEST} dropped successfully.")

        admin_conn.close()  # Close admin connection


@pytest.fixture(scope="function")
def db_cursor(db_conn):
    return db_conn.cursor()


def test_db_ops(db_conn):

    # Setup jobs table
    with db_conn.cursor() as cursor:
        DBUtils.setup_table(db_conn, cursor)
        cursor.execute("SELECT to_regclass('public.jobs');")
        assert cursor.fetchone()[0] is not None, "Table was not created"
        print("Table created successfully.")

    # Insert data from test_data.json into new table
    with db_conn.cursor() as cursor:
        inserted_rows = Data_Processing.process_json('tests/data/test_data.json', db_conn, cursor)
        assert inserted_rows == 3, "Incorrect number of rows inserted"
        print("Data inserted successfully.")

    # Display that all jobs were inserted
    with db_conn.cursor() as cursor:
        cursor.execute("SELECT * FROM jobs;")

        # Fetch all rows
        rows = cursor.fetchall()

        # Print the table header (assuming you know the column names)
        print(
            "Job ID | Title | Company | Description | Location | Min Salary | Max Salary | Salary Time | Posted Date | URL | Remote")
        print("-" * 150)  # Just to create a separator line

        # Print each row
        for row in rows:
            # Assuming the order of columns in 'jobs' table matches the SELECT statement
            print("|".join(str(item).ljust(10) for item in row))

        # Check if the number of rows matches the expected count
        assert len(rows) == 3, "Incorrect number of rows inserted"
        print(f"All {len(rows)} jobs were inserted successfully.")


# Defining mock functions
def mock_parse_salary(obj):
    job_id = obj.get('id')
    if job_id == "f97b4a007d08a432":
        return 71460, 123270
    elif job_id == "5c026a4e9285a29d":
        return 85000, 95000
    elif job_id == "li-4027570412":
        return 0, 0  # or None, None if that's what you expect
    else:
        return None, None  # Default return for other cases


def mock_get_salary_frequency(obj):
    job_id = obj.get('id')
    if job_id == "f97b4a007d08a432":
        return 'yearly'
    elif job_id == "5c026a4e9285a29d":
        return 'yearly'
    elif job_id == "li-4027570412":
        return 'yearly'
    else:
        return None


def mock_get_url(obj):
    job_id = obj.get('id')
    if job_id == "f97b4a007d08a432":
        return "https://www.indeed.com/viewjob?jk=f97b4a007d08a432"
    elif job_id == "5c026a4e9285a29d":
        return "https://www.indeed.com/viewjob?jk=5c026a4e9285a29d"
    elif job_id == "li-4027570412":
        return "https://www.linkedin.com/jobs/view/4027570412"
    else:
        return None


def mock_get_remote_status(obj):
    job_id = obj.get('id')
    if job_id == "f97b4a007d08a432":
        return True
    elif job_id == "5c026a4e9285a29d":
        return False
    elif job_id == "li-4027570412":
        return False
    else:
        return None


@pytest.fixture(scope="module")
def json_test_data():
    with open('tests/data/test_data.json', 'r') as f:
        return [json.loads(line) for line in f]


@pytest.fixture(scope="module")
def expected_results():
    with open('tests/data/expected_results.json', 'r') as f:
        return json.load(f)


@pytest.mark.parametrize("index", [0, 1, 2])  # Pass indices instead
def test_extract_job_data(index, json_test_data, expected_results, mocker):
    input_obj = json_test_data[index]
    expected_output = expected_results[index]

    mocker.patch('src.Data_Processing.parse_salary', side_effect=mock_parse_salary)
    mocker.patch('src.Data_Processing.get_salary_frequency', side_effect=mock_get_salary_frequency)
    mocker.patch('src.Data_Processing.get_url', side_effect=mock_get_url)
    mocker.patch('src.Data_Processing.get_remote_status', side_effect=mock_get_remote_status)

    result = Data_Processing.extract_job_data(input_obj)
    expected_tuple = tuple(expected_output)
    assert result == expected_tuple
